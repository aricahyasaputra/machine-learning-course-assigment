{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aricahyasaputra/machine-learning-course-assigment/blob/main/Minggu%2012%20CNN%20part%202/Tugas_Minggu_12_GoogleNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg8ViqSAOoDe"
      },
      "source": [
        "# GoogleNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPzm22YEOoDj"
      },
      "source": [
        "## Import Required Module(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWg8W2IyOoDl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "# print(os.listdir(\"dataset/flowers\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivm6iOA0OoDq"
      },
      "source": [
        "## CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IDDGfXjPLH0"
      },
      "source": [
        "\n",
        "The Flower Dataset can be acquired from the dataset folder in the repository\n",
        "\n",
        "define Google Drive Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BchDQD8BPb3a",
        "outputId": "218db66d-d9ad-4e94-c5e6-f7bd6340c2aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "baseDirectory = \"/content/drive/My Drive/dataset/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc0FhIMlOoDs"
      },
      "outputs": [],
      "source": [
        "# define parameters\n",
        "\n",
        "CLASS_NUM = 5\n",
        "BATCH_SIZE = 16\n",
        "EPOCH_STEPS = int(4323/BATCH_SIZE)\n",
        "IMAGE_SHAPE = (224, 224, 3)\n",
        "IMAGE_TRAIN = baseDirectory + 'flowers'\n",
        "MODEL_NAME = 'googlenet_flower.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLzvcxYMOoDt",
        "outputId": "f2273956-ad9d-45f5-c357-03c36e5599b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 984 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    #rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "generator_main = train_datagen.flow_from_directory(\n",
        "    IMAGE_TRAIN,\n",
        "    target_size=(IMAGE_SHAPE[0], IMAGE_SHAPE[1]),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMMavBoPOoDu"
      },
      "outputs": [],
      "source": [
        "def my_generator(generator):\n",
        "    while True: # keras requires all generators to be infinite\n",
        "        data = next(generator)\n",
        "        x = data[0]\n",
        "        y = data[1], data[1], data[1]\n",
        "        yield x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHjpHYz3OoDv"
      },
      "outputs": [],
      "source": [
        "train_generator = my_generator(generator_main)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lRHtNbjOoDv"
      },
      "outputs": [],
      "source": [
        "# create model\n",
        "def inception(x, filters):\n",
        "    # 1x1\n",
        "    path1 = Conv2D(filters=filters[0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
        "\n",
        "    # 1x1->3x3\n",
        "    path2 = Conv2D(filters=filters[1][0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
        "    path2 = Conv2D(filters=filters[1][1], kernel_size=(3,3), strides=1, padding='same', activation='relu')(path2)\n",
        "    \n",
        "    # 1x1->5x5\n",
        "    path3 = Conv2D(filters=filters[2][0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
        "    path3 = Conv2D(filters=filters[2][1], kernel_size=(5,5), strides=1, padding='same', activation='relu')(path3)\n",
        "\n",
        "    # 3x3->1x1\n",
        "    path4 = MaxPooling2D(pool_size=(3,3), strides=1, padding='same')(x)\n",
        "    path4 = Conv2D(filters=filters[3], kernel_size=(1,1), strides=1, padding='same', activation='relu')(path4)\n",
        "\n",
        "    return Concatenate(axis=-1)([path1,path2,path3,path4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxQoTdBXOoDw"
      },
      "outputs": [],
      "source": [
        "def auxiliary(x, name=None):\n",
        "    layer = AveragePooling2D(pool_size=(5,5), strides=3, padding='valid')(x)\n",
        "    layer = Conv2D(filters=128, kernel_size=(1,1), strides=1, padding='same', activation='relu')(layer)\n",
        "    layer = Flatten()(layer)\n",
        "    layer = Dense(units=256, activation='relu')(layer)\n",
        "    layer = Dropout(0.4)(layer)\n",
        "    layer = Dense(units=CLASS_NUM, activation='softmax', name=name)(layer)\n",
        "    return layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoZHZG6xOoDw"
      },
      "outputs": [],
      "source": [
        "def googlenet():\n",
        "    layer_in = Input(shape=IMAGE_SHAPE)\n",
        "    \n",
        "    # stage-1\n",
        "    layer = Conv2D(filters=64, kernel_size=(7,7), strides=2, padding='same', activation='relu')(layer_in)\n",
        "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
        "    layer = BatchNormalization()(layer)\n",
        "\n",
        "    # stage-2\n",
        "    layer = Conv2D(filters=64, kernel_size=(1,1), strides=1, padding='same', activation='relu')(layer)\n",
        "    layer = Conv2D(filters=192, kernel_size=(3,3), strides=1, padding='same', activation='relu')(layer)\n",
        "    layer = BatchNormalization()(layer)\n",
        "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
        "\n",
        "    # stage-3\n",
        "    layer = inception(layer, [ 64,  (96,128), (16,32), 32]) #3a\n",
        "    layer = inception(layer, [128, (128,192), (32,96), 64]) #3b\n",
        "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
        "    \n",
        "    # stage-4\n",
        "    layer = inception(layer, [192,  (96,208),  (16,48),  64]) #4a\n",
        "    aux1  = auxiliary(layer, name='aux1')\n",
        "    layer = inception(layer, [160, (112,224),  (24,64),  64]) #4b\n",
        "    layer = inception(layer, [128, (128,256),  (24,64),  64]) #4c\n",
        "    layer = inception(layer, [112, (144,288),  (32,64),  64]) #4d\n",
        "    aux2  = auxiliary(layer, name='aux2')\n",
        "    layer = inception(layer, [256, (160,320), (32,128), 128]) #4e\n",
        "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
        "    \n",
        "    # stage-5\n",
        "    layer = inception(layer, [256, (160,320), (32,128), 128]) #5a\n",
        "    layer = inception(layer, [384, (192,384), (48,128), 128]) #5b\n",
        "    layer = AveragePooling2D(pool_size=(7,7), strides=1, padding='valid')(layer)\n",
        "    \n",
        "    # stage-6\n",
        "    layer = Flatten()(layer)\n",
        "    layer = Dropout(0.4)(layer)\n",
        "    layer = Dense(units=256, activation='linear')(layer)\n",
        "    main = Dense(units=CLASS_NUM, activation='softmax', name='main')(layer)\n",
        "    \n",
        "    model = Model(inputs=layer_in, outputs=[main, aux1, aux2])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSpD7vyROoDx",
        "outputId": "d1c32eaf-dcf4-4446-cb62-0a4d6b549eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 112, 112, 64  9472        ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 56, 56, 64)   0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 56, 56, 64)  256         ['max_pooling2d[0][0]']          \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 56, 56, 64)   4160        ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 56, 56, 192)  110784      ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 56, 56, 192)  768        ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 192)  0          ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 28, 28, 96)   18528       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 28, 28, 16)   3088        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 28, 28, 64)   12352       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 28, 28, 128)  110720      ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 28, 28, 32)   12832       ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 28, 28, 32)   6176        ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 28, 28, 256)  0           ['conv2d_3[0][0]',               \n",
            "                                                                  'conv2d_5[0][0]',               \n",
            "                                                                  'conv2d_7[0][0]',               \n",
            "                                                                  'conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 28, 28, 128)  32896       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 28, 28, 32)   8224        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 256)  0          ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 28, 28, 128)  32896       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 28, 28, 192)  221376      ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 28, 28, 96)   76896       ['conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 28, 28, 64)   16448       ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 28, 28, 480)  0           ['conv2d_9[0][0]',               \n",
            "                                                                  'conv2d_11[0][0]',              \n",
            "                                                                  'conv2d_13[0][0]',              \n",
            "                                                                  'conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 480)  0          ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 14, 14, 96)   46176       ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 14, 14, 16)   7696        ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 14, 14, 480)  0          ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 14, 14, 192)  92352       ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 14, 14, 208)  179920      ['conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 14, 14, 48)   19248       ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 14, 14, 64)   30784       ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 14, 14, 512)  0           ['conv2d_15[0][0]',              \n",
            "                                                                  'conv2d_17[0][0]',              \n",
            "                                                                  'conv2d_19[0][0]',              \n",
            "                                                                  'conv2d_20[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 14, 14, 112)  57456       ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 14, 14, 24)   12312       ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 512)  0          ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 14, 14, 160)  82080       ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 14, 14, 224)  226016      ['conv2d_23[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 14, 14, 64)   38464       ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 14, 14, 64)   32832       ['max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 14, 14, 512)  0           ['conv2d_22[0][0]',              \n",
            "                                                                  'conv2d_24[0][0]',              \n",
            "                                                                  'conv2d_26[0][0]',              \n",
            "                                                                  'conv2d_27[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 14, 14, 128)  65664       ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 14, 14, 24)   12312       ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 14, 14, 512)  0          ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 14, 14, 128)  65664       ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 14, 14, 256)  295168      ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 14, 14, 64)   38464       ['conv2d_31[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 14, 14, 64)   32832       ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 14, 14, 512)  0           ['conv2d_28[0][0]',              \n",
            "                                                                  'conv2d_30[0][0]',              \n",
            "                                                                  'conv2d_32[0][0]',              \n",
            "                                                                  'conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 14, 14, 144)  73872       ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 14, 14, 32)   16416       ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPooling2D)  (None, 14, 14, 512)  0          ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 14, 14, 112)  57456       ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 14, 14, 288)  373536      ['conv2d_35[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 14, 14, 64)   51264       ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 14, 14, 64)   32832       ['max_pooling2d_8[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 14, 14, 528)  0           ['conv2d_34[0][0]',              \n",
            "                                                                  'conv2d_36[0][0]',              \n",
            "                                                                  'conv2d_38[0][0]',              \n",
            "                                                                  'conv2d_39[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 14, 14, 160)  84640       ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 14, 14, 32)   16928       ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPooling2D)  (None, 14, 14, 528)  0          ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 14, 14, 256)  135424      ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 14, 14, 320)  461120      ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 14, 14, 128)  102528      ['conv2d_44[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 14, 14, 128)  67712       ['max_pooling2d_9[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 14, 14, 832)  0           ['conv2d_41[0][0]',              \n",
            "                                                                  'conv2d_43[0][0]',              \n",
            "                                                                  'conv2d_45[0][0]',              \n",
            "                                                                  'conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooling2D  (None, 7, 7, 832)   0           ['concatenate_6[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 7, 7, 160)    133280      ['max_pooling2d_10[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 7, 7, 32)     26656       ['max_pooling2d_10[0][0]']       \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooling2D  (None, 7, 7, 832)   0           ['max_pooling2d_10[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 7, 7, 256)    213248      ['max_pooling2d_10[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 7, 7, 320)    461120      ['conv2d_48[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 7, 7, 128)    102528      ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 7, 7, 128)    106624      ['max_pooling2d_11[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 7, 7, 832)    0           ['conv2d_47[0][0]',              \n",
            "                                                                  'conv2d_49[0][0]',              \n",
            "                                                                  'conv2d_51[0][0]',              \n",
            "                                                                  'conv2d_52[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 7, 7, 192)    159936      ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 7, 7, 48)     39984       ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_12 (MaxPooling2D  (None, 7, 7, 832)   0           ['concatenate_7[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 7, 7, 384)    319872      ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 7, 7, 384)    663936      ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 7, 7, 128)    153728      ['conv2d_56[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 7, 7, 128)    106624      ['max_pooling2d_12[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 7, 7, 1024)   0           ['conv2d_53[0][0]',              \n",
            "                                                                  'conv2d_55[0][0]',              \n",
            "                                                                  'conv2d_57[0][0]',              \n",
            "                                                                  'conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 4, 4, 512)   0           ['concatenate_2[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 4, 4, 528)   0           ['concatenate_5[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 1, 1, 1024)  0           ['concatenate_8[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 4, 4, 128)    65664       ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 4, 4, 128)    67712       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 1024)         0           ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2048)         0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 2048)         0           ['conv2d_40[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 1024)         0           ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 256)          524544      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 256)          524544      ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 256)          262400      ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 256)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 256)          0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " main (Dense)                   (None, 5)            1285        ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " aux1 (Dense)                   (None, 5)            1285        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " aux2 (Dense)                   (None, 5)            1285        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,423,295\n",
            "Trainable params: 7,422,783\n",
            "Non-trainable params: 512\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# train model\n",
        "model = googlenet()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5aj_u7cOoDy"
      },
      "outputs": [],
      "source": [
        "optimizer = ['Adam', 'SGD', 'Adam', 'SGD']\n",
        "epochs = [20, 30, 20, 30]\n",
        "history_all = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3urmG-a8OoDy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c8c6db9-52a7-41f7-bd18-7ee9dfaefb26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usnig optimizer: Adam, Epoch: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "270/270 [==============================] - 84s 256ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 0.8729 - aux1_accuracy: 0.8995 - aux2_accuracy: 0.8678\n",
            "Epoch 2/20\n",
            "270/270 [==============================] - 68s 250ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "270/270 [==============================] - 68s 251ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "270/270 [==============================] - 68s 252ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "270/270 [==============================] - 68s 250ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "270/270 [==============================] - 68s 250ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "270/270 [==============================] - 68s 251ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "270/270 [==============================] - 68s 253ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "270/270 [==============================] - 69s 255ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "270/270 [==============================] - 68s 250ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "270/270 [==============================] - 68s 251ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "270/270 [==============================] - 68s 250ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "270/270 [==============================] - 67s 248ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "270/270 [==============================] - 65s 241ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "270/270 [==============================] - 65s 242ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "270/270 [==============================] - 65s 242ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "270/270 [==============================] - 65s 240ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "270/270 [==============================] - 66s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "270/270 [==============================] - 65s 242ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "270/270 [==============================] - 65s 241ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Usnig optimizer: SGD, Epoch: 30\n",
            "Epoch 1/30\n",
            "270/270 [==============================] - 68s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "270/270 [==============================] - 65s 242ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "270/270 [==============================] - 65s 241ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "270/270 [==============================] - 65s 242ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "270/270 [==============================] - 66s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "270/270 [==============================] - 65s 242ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "270/270 [==============================] - 65s 240ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "270/270 [==============================] - 65s 240ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "270/270 [==============================] - 65s 241ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "270/270 [==============================] - 65s 241ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "270/270 [==============================] - 65s 241ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "270/270 [==============================] - 65s 240ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "270/270 [==============================] - 65s 241ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "270/270 [==============================] - 65s 242ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "270/270 [==============================] - 65s 240ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "270/270 [==============================] - 65s 241ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "270/270 [==============================] - 65s 240ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "270/270 [==============================] - 65s 241ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "270/270 [==============================] - 65s 241ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "270/270 [==============================] - 66s 245ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "270/270 [==============================] - 65s 241ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "270/270 [==============================] - 66s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "270/270 [==============================] - 66s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "270/270 [==============================] - 65s 242ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "270/270 [==============================] - 65s 242ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "270/270 [==============================] - 66s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "270/270 [==============================] - 65s 242ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "270/270 [==============================] - 66s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Usnig optimizer: Adam, Epoch: 20\n",
            "Epoch 1/20\n",
            "270/270 [==============================] - 69s 242ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "270/270 [==============================] - 65s 241ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "270/270 [==============================] - 66s 246ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "270/270 [==============================] - 66s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "270/270 [==============================] - 65s 242ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "270/270 [==============================] - 66s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "270/270 [==============================] - 65s 242ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "270/270 [==============================] - 66s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "270/270 [==============================] - 65s 242ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "270/270 [==============================] - 66s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "270/270 [==============================] - 65s 242ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "270/270 [==============================] - 66s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Usnig optimizer: SGD, Epoch: 30\n",
            "Epoch 1/30\n",
            "270/270 [==============================] - 68s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "270/270 [==============================] - 66s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "270/270 [==============================] - 66s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "270/270 [==============================] - 66s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "270/270 [==============================] - 66s 245ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "270/270 [==============================] - 65s 242ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "270/270 [==============================] - 66s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "270/270 [==============================] - 66s 245ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "270/270 [==============================] - 66s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "270/270 [==============================] - 66s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "270/270 [==============================] - 66s 245ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "270/270 [==============================] - 66s 246ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "270/270 [==============================] - 66s 244ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "270/270 [==============================] - 66s 243ms/step - loss: nan - main_loss: nan - aux1_loss: nan - aux2_loss: nan - main_accuracy: 1.0000 - aux1_accuracy: 1.0000 - aux2_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(optimizer)):\n",
        "    print('Usnig optimizer: ' + optimizer[i] + ', Epoch: ' + str(epochs[i]))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', \n",
        "                  loss_weights={'main': 1.0, 'aux1': 0.3, 'aux2': 0.3},\n",
        "                  optimizer=optimizer[i], metrics=['accuracy'])\n",
        "    \n",
        "    train_history = model.fit_generator(\n",
        "            train_generator,\n",
        "            steps_per_epoch=EPOCH_STEPS,\n",
        "            epochs=epochs[i],\n",
        "            #callbacks=[checkpoint]\n",
        "            shuffle=True\n",
        "            )\n",
        "    \n",
        "    # save history    \n",
        "    if len(history_all) == 0:\n",
        "        history_all = {key: [] for key in train_history.history}\n",
        "    \n",
        "    for key in history_all:\n",
        "        history_all[key].extend(train_history.history[key])\n",
        "\n",
        "model.save(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v0acEClOoDy"
      },
      "outputs": [],
      "source": [
        "# show train history\n",
        "def show_train_history(history, xlabel, ylabel, train):\n",
        "    for item in train:\n",
        "        plt.plot(history[item])\n",
        "    plt.title('Train History')\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.legend(train, loc='upper left')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9HoqtfeOoDy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "cb660d5e-1c3f-473b-8c82-95e96815e6a9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "show_train_history(history_all, 'Epoch', 'Accuracy', ('main_accuracy', 'aux1_accuracy', 'aux2_accuracy'))\n",
        "show_train_history(history_all, 'Epoch', 'Loss', ('main_loss', 'aux1_loss', 'aux2_loss'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Tugas Minggu 12 GoogleNet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "d6f86c6bc9c9469b2c84cfe0cb33110478d210a1f255f386dfb189826f594413"
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 64-bit ('machinelearning': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}